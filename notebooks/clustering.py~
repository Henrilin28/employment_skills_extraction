from sklearn.cluster import KMeans
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.feature_extraction import text 
import nltk.stem
global english_stemmer 
english_stemmer = nltk.stem.SnowballStemmer('english')

class StemmedCountVectorizer(CountVectorizer):
    
    def build_analyzer(self):
        analyzer = super(CountVectorizer, self).build_analyzer()
        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))

def Clustering(df,num_clusters,stop_words):
                 
    stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)
    vectorizer = StemmedCountVectorizer(min_df=10, max_df=0.3,stop_words = stop_words)
    vectorized = vectorizer.fit_transform(df.feature)
    
    km = KMeans(n_clusters = num_clusters, init = 'k-means++', n_init = 1,verbose=1)
    clustered = km.fit(vectorized)
    predict = km.predict(vectorized)
    return predict
